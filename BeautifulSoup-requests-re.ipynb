{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 자료한데모아\n",
    "[공시]\n",
    "[네이버뉴스]\n",
    "[구글뉴스]\n",
    "[종목토론방]\n",
    "[기훈TV]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests as rq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('[공시]')\n",
    "url = 'http://dart.fss.or.kr/api/companyRSS.xml?crpCd=00199252'\n",
    "res = rq.get(url)\n",
    "soup = BeautifulSoup(res.content, 'lxml')\n",
    "titles = soup.find_all('title')\n",
    "for title in titles[1:]:\n",
    "    print(title.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('[네이버뉴스]')\n",
    "url = 'https://search.naver.com/search.naver?where=news&sm=tab_jum'\n",
    "res = rq.get(url, params={'query':'에이치엘비'})\n",
    "soup = BeautifulSoup(res.content, 'lxml')\n",
    "titles = soup.find_all('a', class_=\"_sp_each_title\")\n",
    "for title in titles:\n",
    "    print(title['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('[구글뉴스]')\n",
    "url = 'https://www.google.com/search?sxsrf=ALeKk03UZLKH4Yb88EU6d4Rq8bUi9stgTQ:1582601425545&source=lnms&tbm=nws&sa=X&ved=2ahUKEwinoKne4evnAhVDMN4KHcAnBroQ_AUoAnoECBgQBA&biw=958&bih=959'\n",
    "res = rq.get(url, params={'q':'에이치엘비'})\n",
    "soup = BeautifulSoup(res.content, 'lxml')\n",
    "titles = soup.find_all('div', class_=\"BNeawe vvjwJb AP7Wnd\")\n",
    "for title in titles:\n",
    "    print(title.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('[종목토론방]')\n",
    "url = 'https://finance.naver.com/item/board.nhn?'\n",
    "res = rq.get(url, params={'code':'028300'})\n",
    "soup = BeautifulSoup(res.content, 'lxml')\n",
    "titles = soup.find_all('a', onclick=\"return singleSubmitCheck();\")\n",
    "for title in titles:\n",
    "    print(title['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('[기훈TV]')\n",
    "url = 'https://www.youtube.com/channel/UCP2x9Q7D8tz_pOWD_P5rwCw/videos'\n",
    "res = rq.get(url)\n",
    "soup = BeautifulSoup(res.content, 'lxml')\n",
    "titles = soup.find_all('a', dir=\"ltr\", rel=\"nofollow\", title = True)\n",
    "for title in titles[:10]:\n",
    "    print(title.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('[증권사리포트]')\n",
    "from bs4 import BeautifulSoup\n",
    "import requests as rq\n",
    "corp = []\n",
    "pdf = []\n",
    "\n",
    "url = 'https://finance.naver.com/research/company_list.nhn'\n",
    "res = rq.get(url)\n",
    "soup = BeautifulSoup(res.content, 'lxml')\n",
    "names = soup.find_all('a', class_=\"stock_item\")\n",
    "links = soup.find_all('td', class_=\"file\")\n",
    "\n",
    "for name in names:\n",
    "    corp.append(name['title'])\n",
    "for link in links:\n",
    "    for a in link:\n",
    "        pdf.append(a['href'])\n",
    "\n",
    "result = [x+\": \"+y for x, y in zip(corp, pdf)]\n",
    "for i in result[:10]:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('[구글뉴스링크]')\n",
    "from bs4 import BeautifulSoup\n",
    "import requests as rq\n",
    "import re\n",
    "regex = re.compile('(http|https)(:\\/\\/)(\\w+:{0,1}\\w*@)?(\\S+)(:[0-9]+)?(\\/|\\/([\\w#!:.?+=&%@!\\-\\/]))?(.html)')\n",
    "url = 'https://www.google.com/search?sxsrf=ALeKk03UZLKH4Yb88EU6d4Rq8bUi9stgTQ:1582601425545&source=lnms&tbm=nws&sa=X&ved=2ahUKEwinoKne4evnAhVDMN4KHcAnBroQ_AUoAnoECBgQBA&biw=958&bih=959'\n",
    "res = rq.get(url, params={'q':'에이치엘비'})\n",
    "soup = BeautifulSoup(res.content, 'html')\n",
    "links = soup.find_all('a')\n",
    "for link in links:\n",
    "    text = str(link['href'])\n",
    "    try:\n",
    "        print(''.join(regex.findall(text)[0]))\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
