{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 제약바이오 뉴스기사 스크래핑"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_list = {\n",
    "    \"메디파나\" : \"http://www.medipana.com/news/news_list_new.asp?Page=1&sWord=&sDate=&MainKind=C&NewsKind=67&vCount=20&vKind=1\",\n",
    "    \"약업닷컴\" : \"https://www.yakup.com/news/index.html?cat=12\",\n",
    "    \"바이오스펙테이터\" : \"http://www.biospectator.com/section/section_list.php?MID=11100\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "for url in url_list.keys():\n",
    "    res = requests.get(url_list[url])\n",
    "    soup = BeautifulSoup(res.content, \"lxml\")\n",
    "    \n",
    "    if url == \"메디파나\":\n",
    "        메디파나(soup)\n",
    "    elif url == \"약업닷컴\":\n",
    "        약업닷컴(soup)\n",
    "    elif url == \"바이오스펙테이터\":\n",
    "        바이오스펙테이터(soup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### URL에서 제목, 시간, 링크 추출하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def 메디파나(soup):\n",
    "    \n",
    "    titles = soup.find_all(\"span\", class_=[\"tit\", \"infor\"]) #다중 클래스 선택\n",
    "    i = 0\n",
    "    for title in titles:\n",
    "        print(title.text)\n",
    "        if i % 2 == 1:\n",
    "            print(\"http://www.medipana.com\"+title.parent[\"href\"][2:])\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def 약업닷컴(soup):\n",
    "    \n",
    "    titles = soup.find_all(\"h6\")\n",
    "    for title in titles:\n",
    "        print(title.text)\n",
    "        print(title.next_sibling.next_sibling.next_sibling.next_sibling.next_sibling.next_sibling.next_sibling.next_sibling.text)\n",
    "        print(\"https://www.yakup.com/\"+title.a[\"href\"])       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def 바이오스펙테이터(soup):\n",
    "    titles = soup.find_all(\"strong\", class_=\"article_tit\")\n",
    "    for title in titles:\n",
    "        print(title.text.strip())\n",
    "        print(title.next_sibling.next_sibling.next_sibling.next_sibling.find(\"span\", class_=\"date\").text)\n",
    "        print(\"http://www.biospectator.com/\"+title.a[\"href\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 출처\n",
    "- 다중 클래스 선택 : \n",
    "https://www.it-swarm-ko.tech/ko/python/beautifulsoup-%eb%8b%a4%ec%a4%91-%ed%81%b4%eb%9e%98%ec%8a%a4-%ec%84%a0%ed%83%9d%ea%b8%b0/827508254/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
